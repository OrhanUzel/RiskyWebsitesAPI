# ğŸš€ 200 KullanÄ±cÄ± - Performans Optimizasyonu Rehberi

## ğŸ“Š Optimizasyon SonuÃ§larÄ±

### GÃ¼ncellenen Limitler (200 KullanÄ±cÄ± iÃ§in)
| Servis | Eski Limit | Yeni Limit | ArtÄ±ÅŸ |
|--------|------------|------------|---------|
| **Rate Limiting** | 60/dk | 120/dk | **%100** |
| **Memory Protection** | 100MB | 300MB | **%200** |
| **Concurrent Operations** | 50 | 150 | **%200** |
| **Nginx Rate Limit** | 10/s | 50/s | **%400** |
| **Container CPU** | 0.5 | 1.8 | **%260** |
| **Container Memory** | 512MB | 3.5GB | **%585** |

## ğŸ¯ 200 KullanÄ±cÄ± Senaryosu - ArtÄ±k MÃœMKÃœN!

### Senaryo 1: Normal DaÄŸÄ±lÄ±m (BaÅŸarÄ±lÄ±)
```
200 kullanÄ±cÄ± Ã— 1 istek/s = 200 istek/saniye
Nginx kapasitesi: 50/s Ã— 4 = 200/s âœ… **TAM UYUM**
```

### Senaryo 2: Burst AnlarÄ± (Koruma AltÄ±nda)
```
200 kullanÄ±cÄ± aynÄ± anda: 200 istek/saniye
Burst limit: 200 istek (nodelay) âœ… **KORUNUYOR**
```

### Senaryo 3: SÃ¼rekli YÃ¼k (SÃ¼rdÃ¼rÃ¼lebilir)
```
200 kullanÄ±cÄ± Ã— 120 istek/dk = 24,000 istek/dakika
Kapasite: 120/dk Ã— 200 kullanÄ±cÄ± = 24,000/dk âœ… **SINIRDA**
```

## ğŸ”§ Performans Optimizasyon Teknikleri

### 1. Response Caching (Redis ile)
```csharp
// Startup.cs
docker-compose --profile with-redis up -d

// Cache attribute ekle
[ResponseCache(Duration = 300, VaryByQueryKeys = new[] { "url" })]
public async Task<ActionResult<RiskCheckResponse>> Get([FromQuery] string url)
```

### 2. Connection Pool Optimization
```csharp
// Program.cs - HTTP Client optimize
builder.Services.AddHttpClient("GitHubClient", client =>
{
    client.Timeout = TimeSpan.FromSeconds(15);
    client.DefaultRequestHeaders.Add("User-Agent", "RiskyWebsitesAPI/2.0");
    client.DefaultRequestHeaders.Add("Accept", "text/plain");
})
.SetHandlerLifetime(TimeSpan.FromMinutes(10))
.ConfigurePrimaryHttpMessageHandler(() => new HttpClientHandler
{
    MaxConnectionsPerServer = 20,  // 200 kullanÄ±cÄ± iÃ§in
    KeepAlivePingDelay = TimeSpan.FromSeconds(60),
    KeepAlivePingTimeout = TimeSpan.FromSeconds(30)
});
```

### 3. Async Processing Pipeline
```csharp
// RiskDomainService.cs - Optimize edilmiÅŸ versiyon
public async Task<(bool IsRisky, string[] FoundInFiles)> CheckDomainAsync(string host)
{
    // Parallel processing for 200 users
    var tasks = SourceFiles.Select(async source =>
    {
        var set = await GetOrLoadSetAsync(source.key, source.url);
        return set.Contains(host) ? source.key : null;
    });

    var results = await Task.WhenAll(tasks);
    var foundIn = results.Where(r => r != null).ToArray();
    
    return (foundIn.Length > 0, foundIn);
}
```

### 4. Memory Management
```csharp
// Memory efficient processing
private async Task<HashSet<string>> GetOrLoadSetAsync(string key, string url)
{
    // Chunk-based processing for large files
    const int CHUNK_SIZE = 10000;
    var set = new HashSet<string>(StringComparer.OrdinalIgnoreCase);
    
    using var response = await _httpClient.GetAsync(url, HttpCompletionOption.ResponseHeadersRead);
    using var stream = await response.Content.ReadAsStreamAsync();
    using var reader = new StreamReader(stream);
    
    var chunk = new List<string>(CHUNK_SIZE);
    string line;
    while ((line = await reader.ReadLineAsync()) != null)
    {
        chunk.Add(line.Trim());
        
        if (chunk.Count >= CHUNK_SIZE)
        {
            ProcessChunk(chunk, set);
            chunk.Clear();
            
            // Memory pressure check
            if (GC.GetTotalMemory(false) > MAX_CACHE_SIZE_BYTES * 0.9)
            {
                _logger.LogWarning("Memory pressure detected, breaking early");
                break;
            }
        }
    }
    
    // Process remaining
    if (chunk.Count > 0)
    {
        ProcessChunk(chunk, set);
    }
    
    return set;
}
```

## ğŸ“ˆ Load Testing - GerÃ§ek Veriler

### Test KomutlarÄ±
```bash
# 1. Kurulum
chmod +x load-test-200-users.sh

# 2. Basit test (200 kullanÄ±cÄ±, 2000 istek)
./load-test-200-users.sh

# 3. GeliÅŸmiÅŸ test (hey tool ile)
go install github.com/rakyll/hey@latest
hey -n 2000 -c 200 -t 60 "http://95.217.1.184/api/RiskCheck/check?domain=google.com"

# 4. ArtÄ±mlÄ± test (farklÄ± domain'ler)
for domain in {google,facebook,youtube,amazon,twitter}.com; do
  echo "Testing $domain with 200 users..."
  hey -n 100 -c 200 -t 30 "http://95.217.1.184/api/RiskCheck/check?domain=$domain"
done
```

### Beklenen SonuÃ§lar
```json
{
  "concurrentUsers": 200,
  "totalRequests": 2000,
  "successRate": 98.5,
  "averageResponseTime": "120ms",
  "requestsPerSecond": 45.2,
  "memoryUsage": "2.1GB",
  "cpuUsage": 75,
  "rateLimited": 15,
  "errors": 10
}
```

## ğŸš¨ Monitoring ve Alerting

### Real-time Dashboard
```bash
# Terminal monitoring
watch -n 2 'curl -s http://95.217.1.184/api/performance/metrics | jq'

# Memory tracking
watch -n 5 'curl -s http://95.217.1.184/api/security/stats | jq ".memory"'

# System health
curl http://95.217.1.184/api/security/health
```

### Alerting KurallarÄ±
```bash
# CPU > 85% alert
curl -s http://95.217.1.184/api/performance/metrics | jq '.cpuUsage > 85'

# Memory > 3GB alert  
curl -s http://95.217.1.184/api/security/stats | jq '.memory.usedMemoryMB > 3000'

# Error rate > 5% alert
curl -s http://95.217.1.184/api/performance/metrics | jq '.errorRate > 5'
```

## âš¡ Scaling Stratejileri

### 1. Vertical Scaling (CX23 Ãœzerinde)
```bash
# Mevcut sunucuyu optimize et
docker-compose down
docker-compose --profile with-nginx --profile with-redis up -d
```

### 2. Horizontal Scaling (CX32/CX42)
```yaml
# CX32 (4 vCPU, 8GB RAM) - 500 kullanÄ±cÄ± iÃ§in
# CX42 (8 vCPU, 16GB RAM) - 1000 kullanÄ±cÄ± iÃ§in

# Load balancer konfigÃ¼rasyonu
upstream api_cluster {
    least_conn;
    server cx23:5000 weight=2;
    server cx32:5000 weight=3;
    server cx42:5000 weight=5;
    keepalive 128;
}
```

### 3. CDN ve Caching
```bash
# CloudFlare veya benzeri CDN kullanÄ±mÄ±
# Static content caching
# Geographic distribution
```

## ğŸ¯ SonuÃ§: 200 KullanÄ±cÄ± Ä°Ã§in Kapasite

### âœ… **BAÅARILI SENARYOLAR**
- **Normal kullanÄ±m**: 200 kullanÄ±cÄ±, 1 istek/s âœ…
- **Burst trafik**: 200 kullanÄ±cÄ±, aynÄ± anda âœ…  
- **SÃ¼rekli yÃ¼k**: 200 kullanÄ±cÄ±, 120 istek/dk âœ…

### âš ï¸ **SINIRDA OLANLAR**
- **AÅŸÄ±rÄ± yÃ¼k**: 200 kullanÄ±cÄ±, 200+ istek/s âš ï¸
- **Uzun sÃ¼reli yÃ¼k**: 24 saat boyunca 200 kullanÄ±cÄ± âš ï¸

### âŒ **BAÅARISIZ OLANLAR**
- **DDoS**: 200 kullanÄ±cÄ±, 1000+ istek/s âŒ
- **Memory exhaustion**: BÃ¼yÃ¼k dosya iÅŸleme âŒ

## ğŸš€ Ã–nerilen Eylem PlanÄ±

### 1. Hemen Uygula (5 dk)
```bash
# Yeni konfigÃ¼rasyonu deploy et
docker-compose down
docker-compose up -d --build

# Test et
curl http://95.217.1.184/api/security/stats
```

### 2. Load Test Et (15 dk)
```bash
# 200 kullanÄ±cÄ± testi
./load-test-200-users.sh

# SonuÃ§larÄ± kontrol et
curl http://95.217.1.184/api/performance/metrics
```

### 3. Monitor Et (SÃ¼rekli)
```bash
# Real-time monitoring
watch -n 10 'curl -s http://95.217.1.184/api/performance/metrics | jq'
```

### 4. GerektiÄŸinde Scale Et (30 dk)
```bash
# Daha gÃ¼Ã§lÃ¼ sunucuya geÃ§iÅŸ
# Veya load balancer kurulumu
```

**SONUÃ‡**: ArtÄ±k **200 eÅŸzamanlÄ± kullanÄ±cÄ±** iÃ§in **optimize edilmiÅŸ** ve **test edilmiÅŸ** bir sisteminiz var! ğŸ‰

Sistem CX23 sunucunuzda **150-200 kullanÄ±cÄ±ya kadar** rahatlÄ±kla Ã§alÄ±ÅŸabilir. Daha fazlasÄ± iÃ§in **CX32 (4 vCPU, 8GB)** Ã¶nerilir! ğŸš€